{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "dataframe_dir = '../dataframes/dataframes_by_pos'\n",
    "for pos in os.listdir(dataframe_dir):\n",
    "    pos_dir = os.path.join(dataframe_dir, pos)\n",
    "    for file in os.listdir(pos_dir):\n",
    "        path = os.path.join(pos_dir, file)\n",
    "        assert(os.path.isfile(path))\n",
    "        assert(file.endswith('.csv'))\n",
    "        df_dict[path] = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_df = pd.read_csv('/Users/stevie/repos/lingo_kit_data/dataframes/combined_and_reorganized.csv')\n",
    "ref_df = pd.read_csv('/Users/stevie/repos/lingo_kit_data/dataframes/dataframe_with_audio.csv')\n",
    "len(ref_df), ref_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize part_of_speech values\n",
    "allowed_pos = {'adj', 'adv', 'art', 'conj', 'det', 'noun', 'prep', 'pron', 'verb'}\n",
    "pos_mapping = {\n",
    "    'adj': 'adj',\n",
    "    'adjective': 'adj',\n",
    "    'adjectives': 'adj',\n",
    "    'adv': 'adv',\n",
    "    'adverb': 'adv',\n",
    "    'adverbs': 'adv',\n",
    "    'art': 'art',\n",
    "    'article': 'art',\n",
    "    'articles': 'art',\n",
    "    'conj': 'conj',\n",
    "    'conjunction': 'conj',\n",
    "    'conjunctions': 'conj',\n",
    "    'det': 'det',\n",
    "    'determiner': 'det',\n",
    "    'determiners': 'det',\n",
    "    'noun': 'noun',\n",
    "    'nouns': 'noun',\n",
    "    'prep': 'prep',\n",
    "    'preposition': 'prep',\n",
    "    'prepositions': 'prep',\n",
    "    'pron': 'pron',\n",
    "    'pronoun': 'pron',\n",
    "    'pronouns': 'pron',\n",
    "    'verb': 'verb',\n",
    "    'verbs': 'verb',\n",
    "}\n",
    "def normalize_pos(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "    text = str(value).strip()\n",
    "    key = text.lower()\n",
    "    if key in pos_mapping:\n",
    "        return pos_mapping[key]\n",
    "    if key in allowed_pos:\n",
    "        return key\n",
    "    raise ValueError(f\"Unexpected part_of_speech value: {value!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df['italian_audio_hash'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, df in tqdm(df_dict.items(), total=len(df_dict)):\n",
    "    for i, row in df.iterrows():\n",
    "        pos = normalize_pos(row['part_of_speech'])\n",
    "        # print(pos)\n",
    "        df.loc[i, 'part_of_speech'] = pos\n",
    "        sel_df = ref_df[ref_df['example_sentence_english'] == row['example_sentence_english']]\n",
    "        sel_df = sel_df[sel_df['example_sentence_italian'] == row['example_sentence_italian']]\n",
    "        sel_df = sel_df[sel_df['term_italian'] == row['term_italian']]\n",
    "        sel_df = sel_df[sel_df['translation_english'] == row['translation_english']]\n",
    "        sel_df = sel_df[sel_df['part_of_speech'] == pos]\n",
    "        # print(sel_df['part_of_speech'])\n",
    "        # print(row['part_of_speech'])\n",
    "        if len(sel_df) == 0:\n",
    "            print(f'No match for {row[\"example_sentence_english\"]} / {row[\"example_sentence_italian\"]}')\n",
    "            print(path)\n",
    "            raise Exception('No match found')\n",
    "        if len(sel_df) > 1:\n",
    "            print(f'Multiple matches for {row[\"example_sentence_english\"]} / {row[\"example_sentence_italian\"]}')\n",
    "            print(path)\n",
    "            print(sel_df)\n",
    "            assert(sel_df['italian_audio_hash'].nunique() == 1)\n",
    "            assert(sel_df['english_audio_hash'].nunique() == 1)\n",
    "        # assert(len(sel_df) == 1)\n",
    "        # assert(row['term_italian'] == sel_df.iloc[0]['term_italian'])\n",
    "        # assert(row['translation_english'] == sel_df.iloc[0]['translation_english'])\n",
    "        df.loc[i, 'italian_audio_hash'] = sel_df.iloc[0]['italian_audio_hash']\n",
    "        df.loc[i, 'english_audio_hash'] = sel_df.iloc[0]['english_audio_hash']\n",
    "        df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
