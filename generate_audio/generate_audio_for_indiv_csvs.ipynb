{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH_TO_REPO\"] = \"/Users/stevie/repos/lingo_kit_data\"\n",
    "# os.environ[\"PATH_TO_REPO\"] = \"/home/ubuntu/busy_bees/lingo_kit_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in environment variable\n",
    "import os\n",
    "PATH_TO_REPO = os.getenv('PATH_TO_REPO')\n",
    "assert PATH_TO_REPO is not None, \"Please set PATH_TO_REPO environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import requests\n",
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "import sys\n",
    "sys.path.append(PATH_TO_REPO)\n",
    "from utils.audio.text_to_speech import TextToSpeech, VOICES\n",
    "from utils.s3.upload_to_s3 import upload_file\n",
    "from utils.csv_helper import get_all_csv_files_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.join(PATH_TO_REPO, 'dataframes/dataframes_by_pos')\n",
    "all_csv_files = get_all_csv_files_rec(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = TextToSpeech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_hash(english_text, italian_text):\n",
    "    hash = str(uuid.uuid5(uuid.NAMESPACE_DNS, f\"{english_text}-{italian_text}\"))\n",
    "    return hash\n",
    "print(get_term_hash('person', 'persone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_topics(topics_str):\n",
    "    assert(topics_str[0] == '[' and topics_str[-1] == ']')\n",
    "    topics_str = topics_str[1:-1]  # remove brackets\n",
    "    topics = topics_str.split(',')\n",
    "    return topics\n",
    "\n",
    "def get_language_key(lang):\n",
    "    if lang == 'english':\n",
    "        return 'en'\n",
    "    elif lang == 'italian':\n",
    "        return 'it'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown language: {lang}\")\n",
    "\n",
    "def get_audio_hash(text, voice_name, speaking_rate, pitch):\n",
    "    param_str = f\"{text}{voice_name}{speaking_rate:.2f}{pitch:.2f}\"\n",
    "    hash_object = hashlib.sha256(param_str.encode('utf-8'))\n",
    "    hash_key = hash_object.hexdigest()\n",
    "    return hash_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_csv_processed(df):\n",
    "    for lang in 'english', 'italian':\n",
    "        if f'{lang}_audio_hash' not in df.columns:\n",
    "            return False\n",
    "        if f\"{lang}_duration_ms\" not in df.columns:\n",
    "            return False\n",
    "        if sum(df[f'{lang}_audio_hash'].isna()) > 0:\n",
    "            return False\n",
    "        if sum(df[f'{lang}_duration_ms'].isna()) > 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "new_all_csv_files = []\n",
    "for csv_file in all_csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if not is_csv_processed(df):\n",
    "        new_all_csv_files.append(csv_file)\n",
    "all_csv_files = new_all_csv_files\n",
    "len(all_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_path in tqdm(all_csv_files):\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"File no longer exists, skipping: {csv_path}\")\n",
    "        continue\n",
    "    print(f\"Processing file: {csv_path}\")\n",
    "    file_cost = 0.0\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if is_csv_processed(df):\n",
    "        print(f\"File already processed: {csv_path}\")\n",
    "        continue\n",
    "    for i, (index, row) in enumerate(df.iterrows()):\n",
    "        for lang in 'english', 'italian':\n",
    "            has_hash = f'{lang}_audio_hash' in df.columns and not pd.isna(df.loc[index, f'{lang}_audio_hash'])\n",
    "            has_duration = f'{lang}_duration_ms' in df.columns and not pd.isna(df.loc[index, f'{lang}_duration_ms'])\n",
    "            if has_hash and has_duration:\n",
    "                continue\n",
    "            if lang == 'english':\n",
    "                gender = 'female'\n",
    "                speaking_rate = 0.92\n",
    "                text = row['translation_english']\n",
    "            else:\n",
    "                assert(lang == 'italian')\n",
    "                gender = 'male'\n",
    "                speaking_rate = 0.7\n",
    "                text = row['term_italian']\n",
    "\n",
    "            # this is a fix to make short words like \"a\" or \"the\" followed by parenthesis to sound too short\n",
    "            synth_obj, cost = tts.synthesize(\n",
    "                text=text,\n",
    "                voice_name=VOICES[lang][gender],\n",
    "                speaking_rate=speaking_rate,\n",
    "                verbose=False,\n",
    "            )\n",
    "            file_cost += cost\n",
    "\n",
    "            local_hash = get_audio_hash(\n",
    "                text=text,\n",
    "                voice_name=VOICES[lang][gender],\n",
    "                speaking_rate=speaking_rate,\n",
    "                pitch=synth_obj['pitch'],\n",
    "            )\n",
    "            assert(local_hash == synth_obj['hash']), f\"Hash mismatch: {local_hash} != {synth_obj['hash']}\"\n",
    "\n",
    "            # upload audio file to s3\n",
    "            file_path = os.path.join(PATH_TO_REPO, synth_obj['audio_file'])\n",
    "            assert(os.path.exists(file_path)), f\"File does not exist: {file_path}\"\n",
    "            upload_file(file_path=file_path, verbose=False)\n",
    "\n",
    "            df.loc[index, f'{lang}_audio_hash'] = local_hash\n",
    "            df.loc[index, f'{lang}_duration_ms'] = synth_obj['duration_ms']\n",
    "        print(f\"Processing {i+1}/{len(df)}: {row['term_italian']} / {row['translation_english']} -> {df.loc[index, 'italian_audio_hash']} / {df.loc[index, 'english_audio_hash']}\")\n",
    "    print(f\"Total cost for file {csv_path}: ${file_cost:.6f}\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    tts.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
