{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import requests\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/stevie/repos/language_app\")\n",
    "from utils.text_to_speech import TextToSpeech, VOICES\n",
    "from utils.upload_to_s3 import upload_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,\n",
       " Index(['english', 'italian', 'base_term', 'is_base', 'topic',\n",
       "        'part_of_speech'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first create a dataframe for the text\n",
    "df = pd.read_csv(f\"/Users/stevie/repos/language_app/foundational_words/dataframes/combined.csv\")\n",
    "len(df), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = TextToSpeech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_obj = {\n",
    "#     'english_term': 'person',\n",
    "#     'italian_term': 'persone',\n",
    "#     'base_term': 'person',\n",
    "#     'is_base': True\n",
    "# }\n",
    "# term_obj = requests.post(\n",
    "#     'http://127.0.0.1:8000/create-term',\n",
    "#     json=term_obj,\n",
    "# ).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3cd240e7-7dc2-5554-a776-8111b16dba14\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "def get_term_hash(english_text, italian_text):\n",
    "    hash = str(uuid.uuid5(uuid.NAMESPACE_DNS, f\"{english_text}-{italian_text}\"))\n",
    "    return hash\n",
    "print(get_term_hash('person', 'persone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [04:02<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_language_key(lang):\n",
    "    if lang == 'english':\n",
    "        return 'en'\n",
    "    elif lang == 'italian':\n",
    "        return 'it'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown language: {lang}\")\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # hash\n",
    "    # english_term\n",
    "    # italian_term\n",
    "    # base_term\n",
    "    # is_base\n",
    "    # part_of_speech\n",
    "    # topics\n",
    "    term_hash = get_term_hash(row['english'], row['italian'])\n",
    "    term_obj = {\n",
    "        'hash': term_hash,\n",
    "        'english_term': row['english'],\n",
    "        'italian_term': row['italian'],\n",
    "        'base_term': row['base_term'],\n",
    "        'is_base': row['is_base'],\n",
    "        'part_of_speech': row['part_of_speech'],\n",
    "        'topics': ['Foundational Words'],\n",
    "    }\n",
    "    response = requests.post(\n",
    "        'http://127.0.0.1:8000/create-term',\n",
    "        json=term_obj,\n",
    "    )\n",
    "    term_obj = response.json()\n",
    "    if response.status_code != 201:\n",
    "        # create better handling of term already taken, and add error handling\n",
    "        # print(response.text)\n",
    "        # print(response.status_code)\n",
    "        # print(response.json())\n",
    "        assert(response.json()['hash'][0] == 'term with this hash already exists.')\n",
    "        continue\n",
    "\n",
    "    for lang in 'english', 'italian':\n",
    "        text = row[lang]\n",
    "        # this is a fix to make short words like \"a\" or \"the\" followed by parenthesis to sound too short\n",
    "        text = text.replace(' (', '. (')\n",
    "        synth_obj = tts.synthesize(\n",
    "            text=row[lang],\n",
    "            voice_name=VOICES[lang]['male'],\n",
    "            # speaking_rate=0.75 if lang == 'italian' else 1.0,\n",
    "            speaking_rate=0.75,\n",
    "            pitch=0,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # term\n",
    "        # language\n",
    "        # hash\n",
    "        # speaking_rate\n",
    "        # voice_name\n",
    "        # duration_ms\n",
    "        audio_file_obj = {\n",
    "            'term': term_obj['hash'],\n",
    "            'language': get_language_key(lang),\n",
    "            'hash': synth_obj['hash'],\n",
    "            'speaking_rate': synth_obj['speaking_rate'],\n",
    "            'voice_name': synth_obj['voice_name'],\n",
    "        }\n",
    "        audio_file_obj = requests.post(\n",
    "            'http://127.0.0.1:8000/create-audio-file',\n",
    "            json=audio_file_obj,\n",
    "        ).json()\n",
    "        file_path = os.path.join('/Users/stevie/repos/language_app', synth_obj['audio_file'])\n",
    "        assert(os.path.exists(file_path)), f\"File does not exist: {file_path}\"\n",
    "        upload_file(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved to /Users/stevie/repos/language_app/data/dataframe.csv\n"
     ]
    }
   ],
   "source": [
    "tts.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1435"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tts.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/stevie/repos/language_app/data/audio/70ac481b9b3267885ff18cfa685971fc0274c476758e89dad59a29fcac70b907.mp3'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.df.iloc[0]['audio_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/stevie/repos/language_app/data/audio/ac97dd5e420032640676c224300d47c444b0ee5eeade8017d26f9d1d26dcc479.mp3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.df.iloc[-1]['audio_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the audio file from s3\n",
    "# hash = '9cb7f04b82b5485738f6606c67a1cd43dceadc2c42e006eec2f6dc254ec95d71'\n",
    "# url = f\"https://steviedale-language-app.s3.us-east-1.amazonaws.com/{hash}.mp3\"\n",
    "# file = requests.get(url)\n",
    "# with open('test.mp3', 'wb') as f:\n",
    "#     f.write(file.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# url = f\"https://steviedale-language-app.s3.us-east-1.amazonaws.com/1ed73913-49ff-52ef-898e-eface7fd9f89.mp3\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
